{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ3/iMUOIVaGeciY82nIZ2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tpSnCySWUh18"
      },
      "outputs": [],
      "source": [
        "!pip install openai langchain wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai')\n",
        "openai_api_key=userdata.get('openai')\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('huggingface')\n",
        "huggingface_api_key = userdata.get('huggingface')\n",
        "huggingfacehub_api_token = userdata.get('huggingface')"
      ],
      "metadata": {
        "id": "54BrR8QZVLLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Gji3fWTFoX27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6f11646d"
      },
      "source": [
        "!pip install langchain_openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt3.5\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "\n",
        "llm = OpenAI(api_key=openai_api_key)\n",
        "response = llm.generate([\"농담 하나 해줘\"])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InTULyFsnVCo",
        "outputId": "7f6317d8-bc3a-496e-f261-722f4d78bd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generations=[[Generation(text='\");\\n            jokes.add(\"코로나 때문에 집에만 있으니까 이젠 집주변도 봐줘야하나\");\\n            jokes.add(\"이번에 새로 나온 감염병 이름이 왜 코로나야? 짜증나서 코로나같이 넓게 퍼져가니까\");\\n            jokes.add(\"혹시나 싶어서 코로나 검색하다가 아이러브라면 검색결과가 나오는데 내가 너무 무서워서 울었어\");\\n            jokes.add(\"코로나 확진자는 이제 다 괜찮아졌을거야. 왜냐하면 신종 코로나 바이러스가 이미 더 존나버렸거든\");\\n            jokes.add(\"코로나 때문에 너무 외롭다. 이젠 코로나를 만나러 갈래\");\\n            jokes.add(\"코로', generation_info={'finish_reason': 'length', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 266, 'prompt_tokens': 10, 'completion_tokens': 256}, 'model_name': 'gpt-3.5-turbo-instruct'} run=[RunInfo(run_id=UUID('05ce826a-1db7-4b6d-97ce-9b8534cd4f5e'))] type='LLMResult'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt 4\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-4\")\n",
        "llm.invoke(\"농담 하나 해줘\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6ItqheJo08n",
        "outputId": "36a7df6a-03fb-44fb-bcf7-621be4ea939d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='왜 공부를 엎드려서 해야하나요?\\n\\n모든 지식이 머리로 잘 들어가게 위에서부터 적셔주려고요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 17, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CPmmFeABOm2SVUfvYndyjGSokBjr3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--32fd3771-8e63-4f42-b3a0-1d22316fb8e9-0', usage_metadata={'input_tokens': 17, 'output_tokens': 50, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "e11f6ca0"
      },
      "source": [
        "!pip install langchain_huggingface langchain_community"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7ee865e6"
      },
      "source": [
        "!pip install transformers accelerate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google/flan\n",
        "import langchain\n",
        "from langchain_huggingface import HuggingFaceEndpoint # Changed back to HuggingFaceEndpoint\n",
        "\n",
        "repo_id = \"google/flan-t5-xxl\" # Keeping the model for now\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    huggingfacehub_api_token=huggingface_api_key,\n",
        "    temperature=0.1, # Added temperature and max_new_tokens back\n",
        "    max_new_tokens=64\n",
        ")\n",
        "\n",
        "print(llm.invoke(\"What is the capital of France?\"))"
      ],
      "metadata": {
        "id": "pvGjR8J6plET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}